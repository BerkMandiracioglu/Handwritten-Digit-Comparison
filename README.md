# **Description**
In the context of Image analysis, this paper explores different deep learning architectures for handwritten digit comparison. More precisely, given a pair of handwritten digits the task of our models is to determine which is the bigger digit. Digit Comparison is very related to the popular ML task of handwritten digit recognition. We explore impact of **weight sharing** and **auxiliary losses** on the performances of our networks to solve digit comparison task.

# **Models and Methods**
We have used 5 different neural networks that have different architectures. 3 of them are Convolutional Neural Networks and 2 of them are Fully Connected Neural Networks. Please read the **report.pdf** for details.
# **Discussion & Conclusion**
Our results state that the Convolutional Neural Network using weight sharing and auxiliary losses is the most ef- fective model. It is not surprising since it is the model that best exploits data. Indeed, Adding the auxiliary loss introduces the auxiliary task of learning hand written digits class values besides their comparison, hence it extracts more information from the images. As a result it is the model that best generalizes to the data; the improvement made by the auxiliary losses is also present for the FCN. We observe that the implementation of weight sharing also guarantees an improvement with respect to the CNN. Indeed by sharing a part of the weights, weights were using more data for the training and since they were extracting the same information about each image they did not loose flexibility. Finally, combining the auxiliary losses with weight sharing can increase the performance by up to 8% in terms of accuracy. This extend of performance increase is very crucial in image classification tasks and can really play important role in achieving state-of-the-art results.

